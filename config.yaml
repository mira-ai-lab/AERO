# config.yaml
default:
  initial_model: "http::http://localhost:8001"
  init_model_path: "/root/codespace/hf_resources/Qwen2.5-7B-Instruct"
  
  rounds: 5
  questions_per_round: 1000
  
  sampling_n: 16       # 每个问题生成 N 个回答
  sampling_temp: 0.7   # 采样温度，保证多样性

  llama_factory_dir: "LLaMA-Factory"
  kto_gpus: "4,5"
  
  kto_train_template_yaml: "examples/train_lora/qwen2_5_lora_kto.yaml"
  kto_merge_template_yaml: "examples/merge_lora/qwen2_5_lora_kto.yaml"